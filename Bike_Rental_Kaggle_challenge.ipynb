{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9jX734HKb2X",
        "outputId": "7e13f913-cf07-486b-fd93-649e34e5379a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading bids16-machine-learning, 15050 bytes compressed\n",
            "\r[==================================================] 15050 bytes downloaded\n",
            "Downloaded and uncompressed: bids16-machine-learning\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from tempfile import NamedTemporaryFile\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to download Kaggle data\n",
        "def download_data(data_source_mapping, kaggle_input_path='/kaggle/input', kaggle_working_path='/kaggle/working', chunk_size=40960):\n",
        "  \"\"\"Downloads and uncompresses Kaggle data from a provided URL.\"\"\"\n",
        "  os.makedirs(kaggle_input_path, exist_ok=True)\n",
        "  os.makedirs(kaggle_working_path, exist_ok=True)\n",
        "\n",
        "  for data_source_mapping_item in data_source_mapping.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping_item.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(kaggle_input_path, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(chunk_size)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(chunk_size)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "  print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the data source mapping\n",
        "DATA_SOURCE_MAPPING = 'bids16-machine-learning:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F68885%2F7645460%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240228%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240228T100145Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D04fc00095c8ee62d15debb1245f8e18371d0e0dd151f0f30054d3cfc155ee407d7a56af1c4cc46bc0d97b838cf00948a70fe2a39dcec3c6feb0462f022c6f61c3178a2d40073e8f3b548a381ce59a93c663cd29bc58f70843818098a3fdce0790452a37518eb1dadafd695c7d42eff3c2d5e5f070643237408355965ab5b03684b1acd8ce99b8ddedcd1393c589ba2e2ea99e08bb05b5ec6789e683c7418a2935178eac93e3bc9cc29a06f84e1ea60ea8768437261406254feba5993076420593c875c740446c3fec619e64b723500a7879353980b81049a39ff6ecf217bf8e8c8205f6c2e32dc4c52fed8f711b26e74b8f7bec7bee2e8e6fa7ec57acfad1b28'\n",
        "# Call the function to download the data\n",
        "download_data(DATA_SOURCE_MAPPING)\n",
        "\n",
        "# Paths for Kaggle data input and working directories\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmcdPvR2Kb2a"
      },
      "source": [
        "# Kaggle challenge Yoav Yosef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkMlq4bqKb2g"
      },
      "outputs": [],
      "source": [
        "# Load data using pandas\n",
        "df_train = pd.read_csv(os.path.join(KAGGLE_INPUT_PATH, 'bids16-machine-learning', 'train.csv'))\n",
        "df_test = pd.read_csv(os.path.join(KAGGLE_INPUT_PATH, 'bids16-machine-learning', 'test.csv'))\n",
        "\n",
        "# Copying the train and test data sets to perform tests and feature engineering\n",
        "df_train_copy = df_train.copy()\n",
        "df_test_copy = df_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBclkCBHKb2g"
      },
      "outputs": [],
      "source": [
        "# Dropping 'id' column since it's not required for prediction\n",
        "df_train_copy = df_train_copy.drop(columns=['id'])\n",
        "df_test_copy = df_test_copy.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-oa6k2kjSP7X",
        "outputId": "5b830ee3-f762-45e1-e9b2-3841de531b03"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9GHFVN-cKb2h"
      },
      "outputs": [],
      "source": [
        "# Define the lists of categorical and continuous features\n",
        "categorical_features = ['season', 'mnth', 'weekday', 'workingday', 'weathersit', 'holiday']\n",
        "continuous_features = ['cnt', 'temp', 'atemp', 'hum', 'windspeed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_3R71pFKb2h"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "def check_missing_values(df, title):\n",
        "    \"\"\"Prints missing values in a DataFrame.\"\"\"\n",
        "    print(f\"Missing values in {title}:\\n{df.isnull().sum()}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2blpJVzKb2i",
        "outputId": "4086100c-803d-4f60-fddd-ce220ec43b39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['season', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit',\n",
              "       'temp', 'atemp', 'hum', 'windspeed', 'cnt'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Handle missing values by filling with the median\n",
        "def handle_missing_values(df, title):\n",
        "    \"\"\"Handles missing values in a DataFrame by filling with the median.\"\"\"\n",
        "    for column in df.columns:\n",
        "      if df[column].isnull().any():\n",
        "        median_value = df[column].median()\n",
        "        df[column] = df[column].fillna(median_value)\n",
        "    check_missing_values(df, title)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDwEYQlyKb2i"
      },
      "outputs": [],
      "source": [
        "# Apply the check and handle missing values for train and test sets\n",
        "check_missing_values(df_train_copy, 'training set')\n",
        "df_train_copy = handle_missing_values(df_train_copy, 'training set')\n",
        "check_missing_values(df_test_copy, 'test set')\n",
        "df_test_copy = handle_missing_values(df_test_copy, 'test set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgZoEUP3Kb2i",
        "outputId": "0cc24ece-899e-4d2b-a579-9c1762820350"
      },
      "outputs": [],
      "source": [
        "# Explore data descriptively and visually\n",
        "def explore_data(df, cat_features, num_features):\n",
        "    \"\"\"Explores the data descriptively and visually, including pairplots, correlation matrix and catplots.\"\"\"\n",
        "    print(\"Descriptive statistics for continuous features:\\n\", df[num_features].describe().T)\n",
        "\n",
        "    # Pairplot for continuous features\n",
        "    sns.pairplot(df[num_features])\n",
        "    plt.show()\n",
        "\n",
        "    # Correlation matrix for all features\n",
        "    correlation_matrix = df.corr()\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
        "    plt.title(\"Correlation Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Interaction plots for categorical variables\n",
        "    for cat_feature in cat_features:\n",
        "        sns.catplot(x=cat_feature, y='cnt', data=df, kind='bar')\n",
        "        plt.title(f'{cat_feature} vs cnt')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "explore_data(df_train_copy, categorical_features, continuous_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3MCSRMSS3v_"
      },
      "outputs": [],
      "source": [
        "# Function to calculate wind chill index (WCI) / wind chill factor (WCF)\n",
        "def wind_chill_index(temp, windspeed, temp_scale=10, wind_scale=10):\n",
        "  \"\"\"Calculates the wind chill index using a generic formula with unit scaling.\"\"\"\n",
        "  scaled_temp = temp * temp_scale\n",
        "  scaled_windspeed = windspeed * wind_scale\n",
        "  wind_chill = 35.74 + 0.6215 * scaled_temp - 35.75 * (scaled_windspeed ** 0.16) + 0.4275 * scaled_temp * (scaled_windspeed ** 0.16)\n",
        "  wind_chill_scaled = wind_chill / (temp_scale * wind_scale)\n",
        "  return wind_chill_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_KJqMQ5UAzR"
      },
      "outputs": [],
      "source": [
        "# Function to categorize temperature based on season mean.\n",
        "def categorize_temperature_by_season_simple(temp, season, temp_mean):\n",
        "  \"\"\"Categorizes temperature as \"cold\", \"normal\", or \"hot\" based on season and mean temperature.\"\"\"\n",
        "  if temp < temp_mean * 0.1:  # Cold (10th percentile threshold)\n",
        "    return \"0\"\n",
        "  elif temp > temp_mean * 0.9:  # Hot (90th percentile threshold)\n",
        "    return \"2\"\n",
        "  else:\n",
        "    return \"1\"  # Normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-S5mepqDKb2j",
        "outputId": "8bc30ce8-67ef-47b6-fe49-2d245444af60"
      },
      "outputs": [],
      "source": [
        "# Function to add quarter\n",
        "def add_quarter(df, month_col, quarter_col):\n",
        "  \"\"\"Adds a new feature indicating the quarter of the year (1-4).\"\"\"\n",
        "  df[quarter_col] = (df[month_col] - 1) // 3 + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTdG1besezdA"
      },
      "outputs": [],
      "source": [
        "# Function to add week within a month\n",
        "def add_week_within_month(df, month_col, day_col, week_col):\n",
        "  \"\"\"Adds a new feature indicating the week within the month (1-4 or 5).\"\"\"\n",
        "  year = 2024\n",
        "  df[week_col] = df.apply(lambda row: (math.ceil(pd.Timestamp(year=year,month=row[month_col], day=1).dayofweek + row[day_col]) // 7) +1, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGW5ym_BZvkE"
      },
      "outputs": [],
      "source": [
        "# Calculate mean temperature by season and weather conditions\n",
        "season_mean = df_train_copy.groupby('season')['temp'].mean()\n",
        "weathersit_mean = df_train_copy.groupby('weathersit')['temp'].mean()\n",
        "\n",
        "df_train_copy['temp_mean_by_season'] = df_train_copy['season'].map(season_mean)\n",
        "df_test_copy['temp_mean_by_season'] = df_test_copy['season'].map(season_mean)\n",
        "df_train_copy['temp_mean_by_weathersit'] = df_train_copy['weathersit'].map(weathersit_mean)\n",
        "df_test_copy['temp_mean_by_weathersit'] = df_test_copy['weathersit'].map(weathersit_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGjc4bVzdVMX",
        "outputId": "fdd7b0b0-5842-4bce-c0d1-fab0a87b2473"
      },
      "outputs": [],
      "source": [
        "print(df_train_copy.columns)\n",
        "print(df_train_copy.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTEkAf7DnKG_",
        "outputId": "83237000-c19f-4883-bb92-6c1043c5228a"
      },
      "outputs": [],
      "source": [
        "# Feature engineering with interactions 'temp' and 'atemp'\n",
        "df_train_copy['feels_like_diff'] = df_train_copy['temp'] - df_train_copy['atemp']\n",
        "df_test_copy['feels_like_diff'] = df_test_copy['temp'] - df_test_copy['atemp']\n",
        "df_train_copy['feels_like_ratio'] = df_train_copy['temp'] / df_train_copy['atemp']\n",
        "df_test_copy['feels_like_ratio'] = df_test_copy['temp'] / df_test_copy['atemp']\n",
        "\n",
        "# Feature engineering with interactions 'temp' and 'hum'\n",
        "df_train_copy['temp_hum_interaction'] = df_train_copy['temp'] * df_train_copy['hum']\n",
        "df_test_copy['temp_hum_interaction'] = df_test_copy['temp'] * df_test_copy['hum']\n",
        "\n",
        "# 'hum' 'temp' ratio\n",
        "df_train_copy['hum_temp_ratio'] = df_train_copy['hum'] / df_train_copy['temp']\n",
        "df_test_copy['hum_temp_ratio'] = df_test_copy['hum'] / df_test_copy['temp']\n",
        "\n",
        "# Wind chill\n",
        "df_train_copy['windchill_index'] = wind_chill_index(df_train_copy['temp'], df_train_copy['windspeed'])\n",
        "df_test_copy['windchill_index'] = wind_chill_index(df_test_copy['temp'], df_test_copy['windspeed'])\n",
        "\n",
        "# Transformation features for 'temp'\n",
        "df_train_copy['temp_log'] = np.log(df_train_copy['temp'])\n",
        "df_test_copy['temp_log'] = np.log(df_test_copy['temp'])\n",
        "\n",
        "# Categorize temperature\n",
        "df_train_copy['hot_cold_for_season'] = df_train_copy[['temp', 'season', 'temp_mean_by_season']].apply(lambda row: categorize_temperature_by_season_simple(*row), axis=1)\n",
        "df_test_copy['hot_cold_for_season'] = df_test_copy[['temp', 'season', 'temp_mean_by_season']].apply(lambda row: categorize_temperature_by_season_simple(*row), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "H_UdpO9XeMLa",
        "outputId": "fb32ec98-016e-44d9-c665-8a6958fe8aa8"
      },
      "outputs": [],
      "source": [
        "# Calculate the week within the month and add the quarter\n",
        "add_week_within_month(df_train_copy, df_train_copy['mnth'], df_train_copy['weekday'], 'week_within_month')\n",
        "add_quarter(df_train_copy, df_train_copy['mnth'], 'quarter')\n",
        "add_week_within_month(df_test_copy, df_test_copy['mnth'], df_test_copy['weekday'], 'week_within_month')\n",
        "add_quarter(df_test_copy, df_test_copy['mnth'], 'quarter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhVFZrqdjYAo"
      },
      "outputs": [],
      "source": [
        "# Dropping 'holiday' and 'atemp' column \n",
        "df_train_copy = df_train_copy.drop(columns=['holiday','atemp'])\n",
        "df_test_copy = df_test_copy.drop(columns=['holiday', 'atemp'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouHnW1SdkEKi"
      },
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "def preprocess_data(train_df, test_df):\n",
        "    # List of features to be one-hot encoded\n",
        "    one_hot_features = ['season', 'mnth']\n",
        "\n",
        "    # Select categorical and continuous features in training set\n",
        "    train_categorical = train_df[one_hot_features]\n",
        "    continuous_features = ['cnt', 'temp', 'feels_like_diff', 'feels_like_ratio', 'temp_hum_interaction', 'hum_temp_ratio',\n",
        "                           'windchill_index', 'temp_log']\n",
        "    train_numerical = train_df[continuous_features]\n",
        "\n",
        "    # Select categorical and continuous features in test set\n",
        "    test_categorical = test_df[one_hot_features]\n",
        "    test_continuous_features = [feature for feature in continuous_features if feature != 'cnt']\n",
        "    test_numerical = test_df[test_continuous_features]\n",
        "\n",
        "    # Encode categorical features using pd.get_dummies() with 'category' dtype for both sets\n",
        "    train_encoded = pd.get_dummies(train_categorical, columns=one_hot_features)\n",
        "    test_encoded = pd.get_dummies(test_categorical, columns=one_hot_features)\n",
        "\n",
        "\n",
        "    # Convert boolean values to integers for both sets\n",
        "    train_encoded = train_encoded.astype(int)\n",
        "    test_encoded = test_encoded.astype(int)\n",
        "\n",
        "    # Concatenate numerical and encoded parts for both sets\n",
        "    train_prepared = pd.concat([train_numerical, train_encoded], axis=1)\n",
        "    test_prepared = pd.concat([test_numerical, test_encoded], axis=1)\n",
        "\n",
        "    return train_prepared, test_prepared\n",
        "\n",
        "df_train_prepared, df_test_prepared = preprocess_data(df_train_copy, df_test_copy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAtyVyS5ekeS",
        "outputId": "380ad855-8b9f-4884-c40c-d3e4fbb2c8a6"
      },
      "outputs": [],
      "source": [
        "# Label Encoding 'weathersit'\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "train_label_encode = encoder.fit_transform(df_train_copy['weathersit'])\n",
        "test_label_encode = encoder.fit_transform(df_test_copy['weathersit'])\n",
        "df_train_prepared['label_encode_weathersit'] = train_label_encode\n",
        "df_test_prepared['label_encode_weathersit'] = test_label_encode\n",
        "\n",
        "# Split into training features and training target\n",
        "X_train = df_train_prepared.drop(columns=['cnt'])\n",
        "y_train = df_train_prepared['cnt']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StQuD8SdopfF"
      },
      "outputs": [],
      "source": [
        "# RMSLE function\n",
        "def rmsle(y, y_pred):\n",
        "    assert len(y) == len(y_pred)\n",
        "    terms_to_sum = [\n",
        "        (math.log(max(y_pred[i] + 1e-9, 1)) - math.log(max(y[i] + 1e-9, 1))) ** 2.0\n",
        "        for i, pred in enumerate(y_pred)\n",
        "    ]\n",
        "    return (sum(terms_to_sum) * (1.0 / len(y))) ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyEMd-ZHeuto"
      },
      "outputs": [],
      "source": [
        "# Function to train OLS model\n",
        "def train_ols(X_train, y_train, X_test):\n",
        "    y_train_ols = y_train\n",
        "    X_train_ols = X_train\n",
        "    model_ols = sm.OLS(y_train_ols, X_train_ols)\n",
        "    results_ols = model_ols.fit()\n",
        "    predictions_ols_test = results_ols.predict(X_test)\n",
        "    return predictions_ols_test\n",
        "\n",
        "# Function to train a Decision Tree model\n",
        "def train_decision_tree(X_train, y_train, X_test):\n",
        "    model = DecisionTreeRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions_dev = model.predict(X_test)\n",
        "    return predictions_dev\n",
        "\n",
        "# Function to train a Random Forest model\n",
        "def train_random_forest(X_train, y_train, X_test):\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions_dev = model.predict(X_test)\n",
        "    return predictions_dev\n",
        "\n",
        "# Function to train a Gradient Boosting model\n",
        "def train_adaboost(X_train, y_train, X_test):\n",
        "    model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=5),random_state=42,n_estimators=100, learning_rate=0.1)\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions_dev = model.predict(X_test)\n",
        "    return predictions_dev\n",
        "\n",
        "\n",
        "# Function to train a XGBoost model\n",
        "def train_xgboost(X_train, y_train, X_test):\n",
        "      best_params = {'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
        "      model = XGBRegressor(**best_params, random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions_dev = model.predict(X_test)\n",
        "      return model, predictions_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMc__glGV8Bk"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate different models\n",
        "pred_ols_test = train_ols(X_train, y_train, df_test_prepared)\n",
        "pred_dt_test = train_decision_tree(X_train, y_train, df_test_prepared)\n",
        "pred_rf_test = train_random_forest(X_train, y_train, df_test_prepared)\n",
        "pred_ab_test = train_adaboost(X_train, y_train, df_test_prepared)\n",
        "xgboost_model_1, pred_xgb_test_1 = train_xgboost(X_train, y_train, df_test_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        },
        "id": "VYg9cCPpW9XT",
        "outputId": "005de4f3-3872-454a-ec53-1d121175aea3"
      },
      "outputs": [],
      "source": [
        "# Stacked model\n",
        "from sklearn.ensemble import StackingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Drw1Gt4HL1kt",
        "outputId": "539b2de0-69b2-4286-9a0c-7f42a4e13550"
      },
      "outputs": [],
      "source": [
        "# Define the base models with best parameters\n",
        "xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, gamma =0, subsample = 0.7, colsample_bytree = 1, random_state=42)\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "ada_model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=5),random_state=42,n_estimators=100, learning_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOq7febgi5dA",
        "outputId": "901034b9-b982-43a1-f359-8b1187b27c3d"
      },
      "outputs": [],
      "source": [
        "# Define the final estimator (can be same as one of the base models or a different estimator)\n",
        "final_estimator = LinearRegression()\n",
        "# Define the stacked model\n",
        "stacked_estimators = [\n",
        "    ('xgb', xgb_model),\n",
        "    ('rf', rf_model),\n",
        "    ('ada', ada_model)\n",
        "]\n",
        "stacked_model = StackingRegressor(estimators=stacked_estimators, final_estimator=final_estimator)\n",
        "# Train the stacked model\n",
        "stacked_model.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions_stacked = stacked_model.predict(df_test_prepared)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the final estimator (can be same as one of the base models or a different estimator)\n",
        "final_estimator = LinearRegression()\n",
        "# Define the stacked model\n",
        "stacked_estimators = [\n",
        "    ('xgb', xgb_model),\n",
        "    ('rf', rf_model),\n",
        "    ('ada', ada_model)\n",
        "]\n",
        "stacked_model = StackingRegressor(estimators=stacked_estimators, final_estimator=final_estimator)\n",
        "# Train the stacked model\n",
        "stacked_model.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions_stacked = stacked_model.predict(df_test_prepared)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame for submission\n",
        "submission_df = pd.DataFrame({'id': df_test['id'], 'cnt': predictions_stacked})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Show feature importances\n",
        "print(\"XGBoost feature importances\")\n",
        "plot_feature_importance(xgboost_model_1, df_train_prepared.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the submission file\n",
        "#submission_df.to_csv('/kaggle/working/submission_yoav_stacked.csv', index=False)\n",
        "\n",
        "# Show result\n",
        "#submission_df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 7645460,
          "sourceId": 68885,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

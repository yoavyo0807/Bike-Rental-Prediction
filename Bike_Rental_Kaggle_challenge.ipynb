{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, StackingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from tempfile import NamedTemporaryFile\n",
        "from zipfile import ZipFile\n",
        "import shutil\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import logging\n",
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Constants for wind chill calculation\n",
        "TEMP_SCALE = 10\n",
        "WIND_SCALE = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Configure Logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to download Kaggle data\n",
        "def download_data(data_source_mapping, kaggle_input_path, kaggle_working_path):\n",
        "    \"\"\"Downloads and uncompresses Kaggle data from a provided URL.\"\"\"\n",
        "    os.makedirs(kaggle_input_path, exist_ok=True)\n",
        "    os.makedirs(kaggle_working_path, exist_ok=True)\n",
        "\n",
        "    for data_source_mapping_item in data_source_mapping.split(','):\n",
        "        directory, download_url_encoded = data_source_mapping_item.split(':')\n",
        "        download_url = unquote(download_url_encoded)\n",
        "        filename = urlparse(download_url).path\n",
        "        destination_path = os.path.join(kaggle_input_path, directory)\n",
        "\n",
        "        try:\n",
        "            with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "                total_length = fileres.headers['content-length']\n",
        "                logging.info(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "\n",
        "                shutil.copyfileobj(fileres, tfile)\n",
        "                tfile.flush()\n",
        "\n",
        "                if filename.endswith('.zip'):\n",
        "                    with ZipFile(tfile.name) as zfile:\n",
        "                        zfile.extractall(destination_path)\n",
        "                elif filename.endswith(('.tar', '.tar.gz', '.tgz')):\n",
        "                   with tarfile.open(tfile.name) as tarfile:\n",
        "                        tarfile.extractall(destination_path)\n",
        "                else:\n",
        "                  logging.warning(f\"Unsupported archive format for {filename}, skipping uncompression.\")\n",
        "                \n",
        "                logging.info(f'Downloaded and uncompressed: {directory}')\n",
        "        except HTTPError as e:\n",
        "            logging.error(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "            continue\n",
        "        except OSError as e:\n",
        "            logging.error(f'Failed to load {download_url} to path {destination_path}')\n",
        "            continue\n",
        "    logging.info('Data source import complete.')\n",
        "\n",
        "# Specify the data source mapping\n",
        "DATA_SOURCE_MAPPING = 'bids16-machine-learning:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F68885%2F7645460%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240228%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240228T100145Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D04fc00095c8ee62d15debb1245f8e18371d0e0dd151f0f30054d3cfc155ee407d7a56af1c4cc46bc0d97b838cf00948a70fe2a39dcec3c6feb0462f022c6f61c3178a2d40073e8f3b548a381ce59a93c663cd29bc58f70843818098a3fdce0790452a37518eb1dadafd695c7d42eff3c2d5e5f070643237408355965ab5b03684b1acd8ce99b8ddedcd1393c589ba2e2ea99e08bb05b5ec6789e683c7418a2935178eac93e3bc9cc29a06f84e1ea60ea8768437261406254feba5993076420593c875c740446c3fec619e64b723500a7879353980b81049a39ff6ecf217bf8e8c8205f6c2e32dc4c52fed8f711b26e74b8f7bec7bee2e8e6fa7ec57acfad1b28'\n",
        "\n",
        "def main(kaggle_input_path, kaggle_working_path, submission_file):\n",
        "  # Call the function to download the data\n",
        "  download_data(DATA_SOURCE_MAPPING, kaggle_input_path, kaggle_working_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Load data using pandas\n",
        "df_train = pd.read_csv(os.path.join(kaggle_input_path, 'bids16-machine-learning', 'train.csv'))\n",
        "df_test = pd.read_csv(os.path.join(kaggle_input_path, 'bids16-machine-learning', 'test.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Copying the train and test data sets to perform tests and feature engineering\n",
        "df_train_copy = df_train.copy()\n",
        "df_test_copy = df_test.copy()\n",
        "df_test_copy['id'] = df_test['id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Dropping 'id' column since it's not required for prediction\n",
        "df_train_copy = df_train_copy.drop(columns=['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Define the lists of categorical and continuous features\n",
        "categorical_features = ['season', 'mnth', 'weekday', 'workingday', 'weathersit', 'holiday']\n",
        "continuous_features = ['cnt', 'temp', 'atemp', 'hum', 'windspeed']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "def check_missing_values(df, title):\n",
        "    \"\"\"Prints missing values in a DataFrame.\"\"\"\n",
        "    print(f\"Missing values in {title}:\\n{df.isnull().sum()}\\n\")\n",
        "\n",
        "# Handle missing values by filling with the median\n",
        "def handle_missing_values(df, title):\n",
        "    \"\"\"Handles missing values in a DataFrame by filling with the median.\"\"\"\n",
        "    for column in df.columns:\n",
        "        if df[column].isnull().any():\n",
        "            median_value = df[column].median()\n",
        "            df[column] = df[column].fillna(median_value)\n",
        "    check_missing_values(df, title)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Apply the check and handle missing values for train and test sets\n",
        "check_missing_values(df_train_copy, 'training set')\n",
        "df_train_copy = handle_missing_values(df_train_copy, 'training set')\n",
        "check_missing_values(df_test_copy, 'test set')\n",
        "df_test_copy = handle_missing_values(df_test_copy, 'test set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Explore data descriptively and visually\n",
        "  def explore_data(df, cat_features, num_features):\n",
        "      \"\"\"Explores the data descriptively and visually, including pairplots, correlation matrix and catplots.\"\"\"\n",
        "      print(\"Descriptive statistics for continuous features:\\n\", df[num_features].describe().T)\n",
        "\n",
        "      # Pairplot for continuous features\n",
        "      sns.pairplot(df[num_features])\n",
        "      plt.show()\n",
        "\n",
        "      # Correlation matrix for all features\n",
        "      correlation_matrix = df.corr()\n",
        "      plt.figure(figsize=(10, 8))\n",
        "      sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
        "      plt.title(\"Correlation Matrix\")\n",
        "      plt.show()\n",
        "\n",
        "      # Interaction plots for categorical variables\n",
        "      for cat_feature in cat_features:\n",
        "          sns.catplot(x=cat_feature, y='cnt', data=df, kind='bar')\n",
        "          plt.title(f'{cat_feature} vs cnt')\n",
        "          plt.show()\n",
        "\n",
        "\n",
        "  explore_data(df_train_copy, categorical_features, continuous_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to calculate wind chill index (WCI) / wind chill factor (WCF)\n",
        "  def wind_chill_index(temp, windspeed, temp_scale=TEMP_SCALE, wind_scale=WIND_SCALE):\n",
        "    \"\"\"Calculates the wind chill index using a generic formula with unit scaling.\"\"\"\n",
        "    scaled_temp = temp * temp_scale\n",
        "    scaled_windspeed = windspeed * wind_scale\n",
        "    wind_chill = 35.74 + 0.6215 * scaled_temp - 35.75 * (scaled_windspeed ** 0.16) + 0.4275 * scaled_temp * (scaled_windspeed ** 0.16)\n",
        "    wind_chill_scaled = wind_chill / (temp_scale * wind_scale)\n",
        "    return wind_chill_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to categorize temperature based on season mean.\n",
        "  def categorize_temperature_by_season_simple(temp, season, temp_mean):\n",
        "    \"\"\"Categorizes temperature as \"cold\", \"normal\", or \"hot\" based on season and mean temperature.\"\"\"\n",
        "    if temp < temp_mean * 0.1:  # Cold (10th percentile threshold)\n",
        "      return \"0\"\n",
        "    elif temp > temp_mean * 0.9:  # Hot (90th percentile threshold)\n",
        "      return \"2\"\n",
        "    else:\n",
        "      return \"1\"  # Norma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to add quarter\n",
        "  def add_quarter(df, month_col, quarter_col):\n",
        "    \"\"\"Adds a new feature indicating the quarter of the year (1-4).\"\"\"\n",
        "    df[quarter_col] = (df[month_col] - 1) // 3 + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to add week within a month\n",
        "def add_week_within_month(df, month_col, day_col, week_col):\n",
        "    \"\"\"Adds a new feature indicating the week within the month (1-5).\"\"\"\n",
        "    df[week_col] = df.apply(lambda row: pd.Timestamp(year=2024, month=row[month_col], day=row[day_col]).isocalendar().week, axis=1)\n",
        "    df[week_col] = df.apply(lambda row: math.ceil(pd.Timestamp(year=2024,month=row[month_col], day=1).dayofweek + row[day_col]) // 7, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Calculate mean temperature by season and weather conditions\n",
        "  season_mean = df_train_copy.groupby('season')['temp'].mean()\n",
        "  weathersit_mean = df_train_copy.groupby('weathersit')['temp'].mean()\n",
        "\n",
        "  df_train_copy['temp_mean_by_season'] = df_train_copy['season'].map(season_mean)\n",
        "  df_test_copy['temp_mean_by_season'] = df_test_copy['season'].map(season_mean)\n",
        "  df_train_copy['temp_mean_by_weathersit'] = df_train_copy['weathersit'].map(weathersit_mean)\n",
        "  df_test_copy['temp_mean_by_weathersit'] = df_test_copy['weathersit'].map(weathersit_mean)\n",
        "\n",
        "  # Feature engineering with interactions 'temp' and 'atemp'\n",
        "  df_train_copy['feels_like_diff'] = df_train_copy['temp'] - df_train_copy['atemp']\n",
        "  df_test_copy['feels_like_diff'] = df_test_copy['temp'] - df_test_copy['atemp']\n",
        "  df_train_copy['feels_like_ratio'] = df_train_copy['temp'] / df_train_copy['atemp']\n",
        "  df_test_copy['feels_like_ratio'] = df_test_copy['temp'] / df_test_copy['atemp']\n",
        "\n",
        "  # Feature engineering with interactions 'temp' and 'hum'\n",
        "  df_train_copy['temp_hum_interaction'] = df_train_copy['temp'] * df_train_copy['hum']\n",
        "  df_test_copy['temp_hum_interaction'] = df_test_copy['temp'] * df_test_copy['hum']\n",
        "\n",
        "  # 'hum' 'temp' ratio\n",
        "  df_train_copy['hum_temp_ratio'] = df_train_copy['hum'] / df_train_copy['temp']\n",
        "  df_test_copy['hum_temp_ratio'] = df_test_copy['hum'] / df_test_copy['temp']\n",
        "\n",
        "  # Wind chill\n",
        "  df_train_copy['windchill_index'] = wind_chill_index(df_train_copy['temp'], df_train_copy['windspeed'])\n",
        "  df_test_copy['windchill_index'] = wind_chill_index(df_test_copy['temp'], df_test_copy['windspeed'])\n",
        "\n",
        "  # Transformation features for 'temp'\n",
        "  df_train_copy['temp_log'] = np.log(df_train_copy['temp'])\n",
        "  df_test_copy['temp_log'] = np.log(df_test_copy['temp'])\n",
        "\n",
        "  # Categorize temperature\n",
        "  df_train_copy['hot_cold_for_season'] = df_train_copy[['temp', 'season', 'temp_mean_by_season']].apply(lambda row: categorize_temperature_by_season_simple(*row), axis=1)\n",
        "  df_test_copy['hot_cold_for_season'] = df_test_copy[['temp', 'season', 'temp_mean_by_season']].apply(lambda row: categorize_temperature_by_season_simple(*row), axis=1)\n",
        "\n",
        "  # Calculate the week within the month and add the quarter\n",
        "  add_week_within_month(df_train_copy, df_train_copy['mnth'], df_train_copy['weekday'], 'week_within_month')\n",
        "  add_quarter(df_train_copy, df_train_copy['mnth'], 'quarter')\n",
        "  add_week_within_month(df_test_copy, df_test_copy['mnth'], df_test_copy['weekday'], 'week_within_month')\n",
        "  add_quarter(df_test_copy, df_test_copy['mnth'], 'quarter')\n",
        "\n",
        "  # Dropping 'holiday' and 'atemp' column \n",
        "  df_train_copy = df_train_copy.drop(columns=['holiday','atemp'])\n",
        "  df_test_copy = df_test_copy.drop(columns=['holiday', 'atemp'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "  def preprocess_data(train_df, test_df):\n",
        "      # List of features to be one-hot encoded\n",
        "      one_hot_features = ['season', 'mnth','weekday', 'workingday','hot_cold_for_season','quarter','week_within_month']\n",
        "\n",
        "      # Select categorical and continuous features in training set\n",
        "      train_categorical = train_df[one_hot_features]\n",
        "      continuous_features = ['cnt', 'temp', 'feels_like_diff', 'feels_like_ratio', 'temp_hum_interaction', 'hum_temp_ratio',\n",
        "                            'windchill_index', 'temp_log']\n",
        "      train_numerical = train_df[continuous_features]\n",
        "\n",
        "      # Select categorical and continuous features in test set\n",
        "      test_categorical = test_df[one_hot_features]\n",
        "      test_continuous_features = [feature for feature in continuous_features if feature != 'cnt']\n",
        "      test_numerical = test_df[test_continuous_features]\n",
        "\n",
        "      #Encode Label\n",
        "      encoder = LabelEncoder()\n",
        "      train_label_encode = encoder.fit_transform(df_train_copy['weathersit'])\n",
        "      test_label_encode = encoder.fit_transform(df_test_copy['weathersit'])\n",
        "      \n",
        "      # Encode categorical features using pd.get_dummies() with 'category' dtype for both sets\n",
        "      train_encoded = pd.get_dummies(train_categorical, columns=one_hot_features,dtype=int)\n",
        "      test_encoded = pd.get_dummies(test_categorical, columns=one_hot_features,dtype=int)\n",
        "      \n",
        "      # Concatenate numerical and encoded parts for both sets\n",
        "      train_prepared = pd.concat([train_numerical, train_encoded], axis=1)\n",
        "      test_prepared = pd.concat([test_numerical, test_encoded], axis=1)\n",
        "      \n",
        "      #Label Encode Weathersit\n",
        "      train_prepared['label_encode_weathersit'] = train_label_encode\n",
        "      test_prepared['label_encode_weathersit'] = test_label_encode\n",
        "\n",
        "      return train_prepared, test_prepared\n",
        "\n",
        "  df_train_prepared, df_test_prepared = preprocess_data(df_train_copy, df_test_copy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        " # Split into training features and training target\n",
        "  X_train = df_train_prepared.drop(columns=['cnt'])\n",
        "  y_train = df_train_prepared['cnt']\n",
        "  X_test = df_test_prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        " # RMSLE function\n",
        "  def rmsle(y, y_pred):\n",
        "      assert len(y) == len(y_pred)\n",
        "      terms_to_sum = [\n",
        "          (math.log(max(y_pred[i] + 1e-9, 1)) - math.log(max(y[i] + 1e-9, 1))) ** 2.0\n",
        "          for i, pred in enumerate(y_pred)\n",
        "      ]\n",
        "      return (sum(terms_to_sum) * (1.0 / len(y))) ** 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to train OLS model\n",
        "  def train_ols(X_train, y_train, X_test):\n",
        "    model_ols = sm.OLS(y_train, X_train)\n",
        "    results_ols = model_ols.fit()\n",
        "    predictions_ols_test = results_ols.predict(X_test)\n",
        "    return predictions_ols_test\n",
        "\n",
        "# Function to train a Decision Tree model\n",
        "  def train_decision_tree(X_train, y_train, X_test):\n",
        "      model = DecisionTreeRegressor(random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions_dev = model.predict(X_test)\n",
        "      return predictions_dev\n",
        "\n",
        "  # Function to train a Random Forest model\n",
        "  def train_random_forest(X_train, y_train, X_test):\n",
        "      model = RandomForestRegressor(random_state=42)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions_dev = model.predict(X_test)\n",
        "      return predictions_dev\n",
        "\n",
        "  # Function to train a Gradient Boosting model\n",
        "  def train_adaboost(X_train, y_train, X_test):\n",
        "      model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=5),random_state=42,n_estimators=100, learning_rate=0.1)\n",
        "      model.fit(X_train, y_train)\n",
        "      predictions_dev = model.predict(X_test)\n",
        "      return predictions_dev\n",
        "\n",
        "  # Function to train a XGBoost model\n",
        "  def train_xgboost(X_train, y_train, X_test):\n",
        "        best_params = {'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.7}\n",
        "        model = XGBRegressor(**best_params, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        predictions_dev = model.predict(X_test)\n",
        "        return model, predictions_dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Function to plot feature importance\n",
        "  def plot_feature_importance(model, feature_names):\n",
        "      if hasattr(model, 'feature_importances_'):\n",
        "          feature_importance = model.feature_importances_\n",
        "      elif hasattr(model, 'coef_'):\n",
        "          feature_importance = np.abs(model.coef_)\n",
        "      else:\n",
        "          print(\"Model does not support feature importance.\")\n",
        "          return\n",
        "\n",
        "      feature_importance = pd.Series(feature_importance, index=feature_names)\n",
        "      feature_importance = feature_importance.sort_values(ascending=False)\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      sns.barplot(x=feature_importance.values, y=feature_importance.index)\n",
        "      plt.title(\"Feature Importance\")\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        " # Train and evaluate different models\n",
        "  pred_ols_test = train_ols(X_train, y_train, X_test)\n",
        "  pred_dt_test = train_decision_tree(X_train, y_train, X_test)\n",
        "  pred_rf_test = train_random_forest(X_train, y_train, X_test)\n",
        "  pred_ab_test = train_adaboost(X_train, y_train, X_test)\n",
        "  xgboost_model_1, pred_xgb_test_1 = train_xgboost(X_train, y_train, X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Stacked model\n",
        "  # Define the base models with best parameters\n",
        "  xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, gamma =0, subsample = 0.7, colsample_bytree = 1, random_state=42)\n",
        "  rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "  ada_model = AdaBoostRegressor(DecisionTreeRegressor(max_depth=5),random_state=42,n_estimators=100, learning_rate=0.1)\n",
        "  # Define the final estimator (can be same as one of the base models or a different estimator)\n",
        "  final_estimator = LinearRegression()\n",
        "  # Define the stacked model\n",
        "  stacked_estimators = [\n",
        "      ('xgb', xgb_model),\n",
        "      ('rf', rf_model),\n",
        "      ('ada', ada_model)\n",
        "  ]\n",
        "  stacked_model = StackingRegressor(estimators=stacked_estimators, final_estimator=final_estimator)\n",
        "  # Train the stacked model\n",
        "  stacked_model.fit(X_train, y_train)\n",
        "  # Make predictions on the test set\n",
        "  predictions_stacked = stacked_model.predict(df_test_prepared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame for submission\n",
        "  submission_df = pd.DataFrame({'id': df_test_copy['id'], 'cnt': predictions_stacked})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "#Show feature importances\n",
        "  print(\"XGBoost feature importances\")\n",
        "  plot_feature_importance(xgboost_model_1, df_train_prepared.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Save the submission file\n",
        "submission_df.to_csv(submission_file, index=False)\n",
        "\n",
        "# Show result\n",
        "print(submission_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  parser = argparse.ArgumentParser(description='Download data, train models, and make submissions.')\n",
        "  parser.add_argument('--input_path', type=str, default='/kaggle/input', help='Path to the input data.')\n",
        "  parser.add_argument('--working_path', type=str, default='/kaggle/working', help='Path to the working directory.')\n",
        "  parser.add_argument('--submission_file', type=str, default='submission.csv', help='Path to the submission file.')\n",
        "  args = parser.parse_args()\n",
        "  main(args.input_path, args.working_path, args.submission_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 7645460,
          "sourceId": 68885,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
